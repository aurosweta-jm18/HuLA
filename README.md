# HuLA: Prosody-Aware Anti-Spoofing with Multi-task Learning for Expressive and Emotional Speech
Aurosweta Mahapatra Student Member, IEEE, Ismail Rasim Ulgen Student Member, IEEE, Berrak Sisman Senior Member, IEEE

Submitted to IEEE Transactions on Affective Computing
[Paper Link](https://www.arxiv.org/abs/2509.21676)

Codes will be available shortly.

## Pre-trained Models

**Link to pre-trained models:**  
[Pre-tranied Models](https://drive.google.com/drive/folders/13I6dSEvkMtAOJP9qqBMiS0aCd1SdblAJ?usp=drive_link)

We have uploaded all the three models:

1. **HuLA without Pre-training**  
2. **First stage Multi-task Learning on Real Data**  
3. **HuLA: Full two stage MTL**

We loaded the pretrained XLS-R model from Hugging Face for this work. ([XLS-R](https://huggingface.co/facebook/wav2vec2-xls-r-300m))

First-stage training data: [Librispeech](https://www.openslr.org/12)

Second-stage training data: [ASVspoof-2019](https://datashare.ed.ac.uk/handle/10283/3336)

(Please refer to the paper for more details)
